{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from /home/vinicius.mello/Workspace/SonarAnalysis/Results/NoveltyDetection/NeuralNetwork/outputs/35038f1fdb900e374ada1a03b216d979926b694e68f8ca24cc3d74914e8c1f37/parameters.json\n",
      "[+] Time to read data file: 1.39137101173 seconds\n",
      "Qtd event of A is 12939\n",
      "Qtd event of B is 29352\n",
      "Qtd event of C is 11510\n",
      "Qtd event of D is 23760\n",
      "\n",
      "Biggest class is B with 29352 events\n",
      "Total of events in the dataset is 77561\n",
      "Balacing data...\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (12939, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (29352, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (11510, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (23760, 400)\n",
      "Reading from /home/vinicius.mello/Workspace/SonarAnalysis/Results/NoveltyDetection/4_folds_cross_validation_balanced_data.jbl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from noveltyDetectionConfig import CONFIG\n",
    "import numpy as np\n",
    "import itertools\n",
    "import multiprocessing\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from NNNoveltyDetectionAnalysis import NNNoveltyDetectionAnalysis\n",
    "\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "from Functions.telegrambot import Bot\n",
    "\n",
    "my_bot = Bot(\"lisa_thebot\")\n",
    "\n",
    "# Enviroment variables\n",
    "data_path = CONFIG['OUTPUTDATAPATH']\n",
    "results_path = CONFIG['PACKAGE_NAME']\n",
    "\n",
    "training_params = {\n",
    "    \"Technique\": \"NeuralNetwork\",\n",
    "    \"DevelopmentMode\": False,\n",
    "    \"DevelopmentEvents\": 400,\n",
    "}\n",
    "analysis = NNNoveltyDetectionAnalysis(parameters=training_params, \n",
    "                                      model_hash=\"35038f1fdb900e374ada1a03b216d979926b694e68f8ca24cc3d74914e8c1f37\", \n",
    "                                      load_hash=True, load_data=True, verbose=True)\n",
    "all_data, all_trgt, all_trgt_sparse = analysis.getData()\n",
    "\n",
    "trn_data = analysis.trn_data\n",
    "trn_trgt = analysis.trn_trgt\n",
    "trn_trgt_sparse = analysis.trn_trgt_sparse\n",
    "\n",
    "models = analysis.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose layer \n",
    "layer = 1\n",
    "\n",
    "# Choose neurons topology\n",
    "hidden_neurons = [50]\n",
    "\n",
    "step = 5\n",
    "neurons_mat = [1] + range(step,hidden_neurons[layer-1]+step,step)\n",
    "neurons_mat = neurons_mat[:len(neurons_mat)-layer+2]\n",
    "\n",
    "analysis_name = 'feature_relevance_analysis_%i_layer'%(layer)\n",
    "analysis_file = os.path.join(analysis.getBaseResultsPath(), \"AnalysisFiles\", analysis_name + \".jbl\")    \n",
    "\n",
    "verbose = True\n",
    "\n",
    "# Plot parameters\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['legend.numpoints'] = 1\n",
    "plt.rcParams['legend.handlelength'] = 3\n",
    "plt.rcParams['legend.borderpad'] = 0.3\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "m_colors = ['b', 'r', 'g', 'y']\n",
    "figsize = (10,5)\n",
    "\n",
    "n_bins = all_data.shape[1]\n",
    "sp_per_bin = np.zeros(n_bins)\n",
    "for ibin in range(n_bins):\n",
    "    temp_all_data = all_data[:,:]\n",
    "    temp_all_data[:,ibin] = 0\n",
    "    \n",
    "    #Get SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
