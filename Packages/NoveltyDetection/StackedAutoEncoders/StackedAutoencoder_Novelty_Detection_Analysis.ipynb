{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Marinha do Brasil\n",
    "\n",
    "## Laboratório de Processamento de Sinais - UFRJ\n",
    "\n",
    "### Autor: Vinícius dos Santos Mello <viniciusdsmello@poli.ufrj.br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Time to read data file: 1.05872392654 seconds\n",
      "Qtd event of A is 12939\n",
      "Qtd event of B is 29352\n",
      "Qtd event of C is 11510\n",
      "Qtd event of D is 23760\n",
      "\n",
      "Biggest class is B with 29352 events\n",
      "Total of events in the dataset is 77561\n",
      "Balacing data...\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (12939, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (29352, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (11510, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (23760, 400)\n",
      "Reading from /home/vinicius.mello/Workspace/SonarAnalysis_2/Results/NoveltyDetection/4_folds_cross_validation_balanced_data.jbl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from noveltyDetectionConfig import CONFIG\n",
    "import numpy as np\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import pprint \n",
    "\n",
    "from SAENoveltyDetectionAnalysis import SAENoveltyDetectionAnalysis\n",
    "\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "from Functions.telegrambot import Bot\n",
    "\n",
    "my_bot = Bot(\"lisa_thebot\")\n",
    "\n",
    "# Enviroment variables\n",
    "data_path = CONFIG['OUTPUTDATAPATH']\n",
    "results_path = CONFIG['PACKAGE_NAME']\n",
    "\n",
    "training_params = {\n",
    "    \"Technique\": \"StackedAutoEncoder\",\n",
    "    \"TechniqueParameters\": {\n",
    "        \"allow_change_weights\": False #False\n",
    "    },\n",
    "    \"DevelopmentMode\": False,\n",
    "    \"DevelopmentEvents\": 400,\n",
    "    \"NoveltyDetection\": True,\n",
    "    \"InputDataConfig\": {\n",
    "        \"database\": \"4classes\",\n",
    "        \"n_pts_fft\": 1024,\n",
    "        \"decimation_rate\": 3,\n",
    "        \"spectrum_bins_left\": 400,\n",
    "        \"n_windows\": 1,\n",
    "        \"balance_data\": True\n",
    "    },\n",
    "    \"OptmizerAlgorithm\": {\n",
    "        \"name\": \"Adam\",\n",
    "        \"parameters\": {\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"beta_1\": 0.90,\n",
    "            \"beta_2\": 0.999,\n",
    "            \"epsilon\": 1e-08,\n",
    "            \"learning_decay\": 1e-6,\n",
    "            \"momentum\": 0.3,\n",
    "            \"nesterov\": True\n",
    "        }\n",
    "    },\n",
    "    \"HyperParameters\": {\n",
    "        \"n_folds\": 4,#10, #4,\n",
    "        #\"n_epochs\": 300,#500,\n",
    "        \"pretraining_n_epochs\": 300,\n",
    "        \"finetuning_n_epochs\": 300,\n",
    "        \"n_inits\": 1,#1, #2,\n",
    "        \"batch_size\": 128,#128, #256,\n",
    "        \"kernel_initializer\": \"uniform\",\n",
    "        \"bias_initializer\": \"ones\", #zeros\n",
    "        \"encoder_activation_function\": \"sigmoid\",\n",
    "        \"decoder_activation_function\": \"sigmoid\",\n",
    "        \"classifier_output_activation_function\": \"sigmoid\",\n",
    "        \"norm\": \"mapstd\",\n",
    "        \"metrics\": [\"accuracy\"],\n",
    "        \"loss\": \"mean_squared_error\",\n",
    "        \"dropout\": False,\n",
    "        \"dropout_parameter\": 0.00,\n",
    "        \"regularization\": None, #None\n",
    "        \"regularization_parameter\": 0.00 #0.00\n",
    "    },\n",
    "    \"callbacks\": {\n",
    "        \"EarlyStopping\": {\n",
    "            \"patience\": 30,\n",
    "            \"monitor\": \"val_loss\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "analysis = SAENoveltyDetectionAnalysis(parameters=training_params,\n",
    "                                       model_hash=\"\",\n",
    "                                       load_hash=False, load_data=True, verbose=True)\n",
    "all_data, all_trgt, trgt_sparse = analysis.getData()\n",
    "\n",
    "SAE = analysis.createSAEModels()\n",
    "\n",
    "trn_data = analysis.trn_data\n",
    "trn_trgt = analysis.trn_trgt\n",
    "trn_trgt_sparse = analysis.trn_trgt_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e0778959d0a01951aac45a34a4a6055ec2bb3f5a484d83c63458c65d59d93257\n",
      "/home/vinicius.mello/Workspace/SonarAnalysis_2/Results/NoveltyDetection/StackedAutoEncoder/outputs/e0778959d0a01951aac45a34a4a6055ec2bb3f5a484d83c63458c65d59d93257\n",
      "{'DevelopmentEvents': 400,\n",
      " 'DevelopmentMode': False,\n",
      " 'HyperParameters': {'batch_size': 128,\n",
      "                     'bias_initializer': 'ones',\n",
      "                     'classifier_output_activation_function': 'sigmoid',\n",
      "                     'decoder_activation_function': 'sigmoid',\n",
      "                     'dropout': False,\n",
      "                     'dropout_parameter': 0.0,\n",
      "                     'encoder_activation_function': 'sigmoid',\n",
      "                     'finetuning_n_epochs': 300,\n",
      "                     'kernel_initializer': 'uniform',\n",
      "                     'loss': 'mean_squared_error',\n",
      "                     'metrics': ['accuracy'],\n",
      "                     'n_folds': 4,\n",
      "                     'n_inits': 4,\n",
      "                     'norm': 'mapstd',\n",
      "                     'pretraining_n_epochs': 300,\n",
      "                     'regularization': None,\n",
      "                     'regularization_parameter': 0.0},\n",
      " 'InputDataConfig': {'balance_data': True,\n",
      "                     'database': '4classes',\n",
      "                     'decimation_rate': 3,\n",
      "                     'n_pts_fft': 1024,\n",
      "                     'n_windows': 1,\n",
      "                     'spectrum_bins_left': 400},\n",
      " 'NoveltyDetection': True,\n",
      " 'OptmizerAlgorithm': {'name': 'Adam',\n",
      "                       'parameters': {'beta_1': 0.9,\n",
      "                                      'beta_2': 0.999,\n",
      "                                      'epsilon': 1e-08,\n",
      "                                      'learning_decay': 1e-06,\n",
      "                                      'learning_rate': 0.001,\n",
      "                                      'momentum': 0.3,\n",
      "                                      'nesterov': True}},\n",
      " 'Technique': 'StackedAutoEncoder',\n",
      " 'TechniqueParameters': {'allow_change_weights': False},\n",
      " 'callbacks': {'EarlyStopping': {'monitor': 'val_loss', 'patience': 30}}}\n"
     ]
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "print analysis.model_hash\n",
    "print analysis.getBaseResultsPath()\n",
    "pp.pprint(analysis.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python sae_train.py --layer 1 --novelty 0 --finetunning 1 --threads 8 --type neuronSweep --hiddenNeurons 400x350x300x250x200x150x100x50 --neuronsVariationStep 50 --modelhash 73b6bb9fc265bc775379a0d422a1a35f487edbfb37c2ff99a77f9e7a1a4dd1f5\n"
     ]
    }
   ],
   "source": [
    "for inovelty in range(len(analysis.class_labels)):\n",
    "    startTime = time.time()\n",
    "    \n",
    "    data=trn_data[inovelty]\n",
    "    trgt=trn_trgt[inovelty]\n",
    "    trainingType = \"neuronSweep\"\n",
    "    analysis.train(layer=1,\n",
    "                   inovelty=inovelty,\n",
    "                   fineTuning=True,\n",
    "                   trainingType=trainingType, #foldSweep, neuronSweep, normal, layerSweep\n",
    "                   hidden_neurons=[400,350,300,250,200,150,100,50],\n",
    "                   neurons_variation_step=50,\n",
    "                   numThreads=8,\n",
    "                   model_hash=analysis.model_hash)\n",
    "    \n",
    "    duration = str(timedelta(seconds=float(time.time() - startTime)))\n",
    "    print \"The training of the model for novelty class {0} took {1} to be performed\\n\".format(analysis.class_labels[inovelty], duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n",
      "0.25\n",
      "0.5\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DevelopmentEvents': 400,\n",
       " 'DevelopmentMode': False,\n",
       " 'HyperParameters': {'batch_size': 128,\n",
       "  'bias_initializer': 'ones',\n",
       "  'classifier_output_activation_function': 'sigmoid',\n",
       "  'decoder_activation_function': 'sigmoid',\n",
       "  'dropout': False,\n",
       "  'dropout_parameter': 0.0,\n",
       "  'encoder_activation_function': 'sigmoid',\n",
       "  'kernel_initializer': 'uniform',\n",
       "  'loss': 'mean_squared_error',\n",
       "  'metrics': ['accuracy'],\n",
       "  'n_epochs': 50,\n",
       "  'n_folds': 4,\n",
       "  'n_inits': 1,\n",
       "  'norm': 'mapminmax',\n",
       "  'regularization': None,\n",
       "  'regularization_parameter': 1},\n",
       " 'InputDataConfig': {'balance_data': True,\n",
       "  'database': '4classes',\n",
       "  'decimation_rate': 3,\n",
       "  'n_pts_fft': 1024,\n",
       "  'n_windows': 1,\n",
       "  'spectrum_bins_left': 400},\n",
       " 'NoveltyDetection': True,\n",
       " 'OptmizerAlgorithm': {'name': 'Adam',\n",
       "  'parameters': {'beta_1': 0.9,\n",
       "   'beta_2': 0.999,\n",
       "   'epsilon': 1e-08,\n",
       "   'learning_decay': 1e-06,\n",
       "   'learning_rate': 0.001,\n",
       "   'momentum': 0.3,\n",
       "   'nesterov': True}},\n",
       " 'Technique': 'StackedAutoEncoder',\n",
       " 'TechniqueParameters': {'allow_change_weights': False},\n",
       " 'callbacks': {'EarlyStopping': {'monitor': 'val_loss', 'patience': 30}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "num_values = 4\n",
    "gridSearch = [copy.deepcopy(training_params) for i in range(num_values)]\n",
    "for params in gridSearch:\n",
    "    params['HyperParameters']['regularization_parameter'] = 2**-i\n",
    "    print params['HyperParameters']['regularization_parameter']\n",
    "    i = i - 1\n",
    "    \n",
    "gridSearch[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
