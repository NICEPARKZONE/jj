{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Classificação para Marinha do Brasil\n",
    "\n",
    "## Autor: Natanael Junior (natmourajr@gmail.com)\n",
    "\n",
    "Laboratório de Processamento de Sinais - UFRJ\n",
    "\n",
    "Laboratório de Tecnologia Sonar\n",
    "\n",
    "Instituto de Pesquisas da Marinha - IPqM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas e leitura dos dados\n",
    "As bibliotecas necessárias para a inclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to import all libraries: 0.50086 seconds\n",
      "Time to read data file: 1.58458 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "init_time = time.time()\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "m_time = time.time()\n",
    "print 'Time to import all libraries: %1.5f seconds'%(m_time-init_time)\n",
    "\n",
    "outputpath = os.environ['OUTPUTDATAPATH']\n",
    "main_analysis_path = os.environ['SONAR_WORKSPACE']\n",
    "log_analysis_path = os.environ['PACKAGE_OUTPUT']\n",
    "result_analysis_path = os.environ['PACKAGE_OUTPUT']+'/PCASingleClassSVM'\n",
    "# Read data\n",
    "# Check if LofarData has created...\n",
    "m_time = time.time()\n",
    "\n",
    "\n",
    "subfolder = '4classes_old'\n",
    "n_pts_fft = 1024\n",
    "decimation_rate = 3\n",
    "\n",
    "if(not os.path.exists(outputpath+'/'+'LofarData_%s_%i_fft_pts_%i_decimation_rate.jbl'%(\n",
    "            subfolder,n_pts_fft,decimation_rate))):\n",
    "    print outputpath+'/'+'LofarData_%s_%i_fft_pts_%i_decimation_rate.jbl'%(\n",
    "        subfolder,n_pts_fft,decimation_rate)+' doesnt exist...please create it'\n",
    "    exit()\n",
    "    \n",
    "#Read lofar data\n",
    "[data,class_labels] = joblib.load(outputpath+'/'+'LofarData_%s_%i_fft_pts_%i_decimation_rate.jbl'%(\n",
    "            subfolder,n_pts_fft,decimation_rate))\n",
    "\n",
    "m_time = time.time()-m_time\n",
    "print 'Time to read data file: %1.5f seconds'%m_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento dos dados\n",
    "Os dados encontram-se no formato do matlab, para isso precisam ser processados para o formato de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process data...\n",
    "# create a full data vector\n",
    "all_data = {};\n",
    "all_trgt = {};\n",
    "\n",
    "for iclass, class_label in enumerate(class_labels):\n",
    "    for irun in range(len(data[iclass])):\n",
    "        if len(all_data) == 0:\n",
    "            all_data = data[iclass][irun]['Signal']\n",
    "            all_trgt = (iclass)*np.ones(data[iclass][irun]['Signal'].shape[1])\n",
    "        else:\n",
    "            all_data = np.append(all_data,data[iclass][irun]['Signal'],axis=1)\n",
    "            all_trgt = np.append(all_trgt,(iclass)*np.ones(data[iclass][irun]\n",
    "                                                           ['Signal'].shape[1]),axis=0)\n",
    "            \n",
    "all_data = all_data.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanceamento de Classes\n",
    "Os dados encontram-se desbalanceados. Com isso, os classificadores podem se especializar em uma classe (gerando mais SVs para a mesma) e não se especializar em outras\n",
    "\n",
    "Acessados em 21/12/2016\n",
    "\n",
    "https://svds.com/learning-imbalanced-classes/\n",
    "\n",
    "http://www.cs.utah.edu/~piyush/teaching/ImbalancedLearning.pdf\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html\n",
    "\n",
    "Para solucionar isso, a primeira solução é \"criar\" dados das classes com menos eventos de maneira aleatória. Outras soluções podem ser propostas posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd event of ClassA is 4312\n",
      "Qtd event of ClassB is 9781\n",
      "Qtd event of ClassC is 3833\n",
      "Qtd event of ClassD is 7918\n",
      "\n",
      "Biggest class is ClassB with 9781 events\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (4312, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (9781, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (3833, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (7918, 400)\n"
     ]
    }
   ],
   "source": [
    "# Process data\n",
    "# unbalanced data to balanced data with random data creation of small classes\n",
    "\n",
    "# Same number of events in each class\n",
    "qtd_events_biggest_class = 0\n",
    "biggest_class_label = ''\n",
    "\n",
    "for iclass, class_label in enumerate(class_labels):\n",
    "    if sum(all_trgt==iclass) > qtd_events_biggest_class:\n",
    "        qtd_events_biggest_class = sum(all_trgt==iclass)\n",
    "        biggest_class_label = class_label\n",
    "    print \"Qtd event of %s is %i\"%(class_label,sum(all_trgt==iclass))\n",
    "print \"\\nBiggest class is %s with %i events\"%(biggest_class_label,qtd_events_biggest_class)\n",
    "\n",
    "\n",
    "balanced_data = {}\n",
    "balanced_trgt = {}\n",
    "\n",
    "from Functions import DataHandler as dh\n",
    "m_datahandler = dh.DataHandlerFunctions()\n",
    "\n",
    "for iclass, class_label in enumerate(class_labels):\n",
    "    if len(balanced_data) == 0:\n",
    "        class_events = all_data[all_trgt==iclass,:]\n",
    "        balanced_data = m_datahandler.CreateEventsForClass(\n",
    "            class_events,qtd_events_biggest_class-(len(class_events)))\n",
    "        balanced_trgt = (iclass)*np.ones(qtd_events_biggest_class)\n",
    "    else:\n",
    "        balanced_data = np.append(balanced_data,\n",
    "                                  (m_datahandler.CreateEventsForClass(\n",
    "                    all_data[all_trgt==iclass,:],\n",
    "                    qtd_events_biggest_class-sum(all_trgt==iclass))),\n",
    "                                  axis=0)\n",
    "        balanced_trgt = np.append(balanced_trgt,\n",
    "                                  (iclass)*np.ones(qtd_events_biggest_class),axis=0)\n",
    "        \n",
    "all_data = balanced_data\n",
    "all_trgt = balanced_trgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definições do treinamento\n",
    "Nessa célula temos os parâmetros do treinamento a ser realizado. No log, deve ficar armazenada a data do treinamento para a reconstrução dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n",
      "Dividing data in trn and tst for novelty class: ClassA\n",
      "Dividing data in trn and tst for novelty class: ClassB\n",
      "Dividing data in trn and tst for novelty class: ClassC\n",
      "Dividing data in trn and tst for novelty class: ClassD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/natmourajr/Workspace/Doutorado/SonarAnalysis/Results/NoveltyDetection/PCASingleClassSVM/train_info_files/2017_03_18_19_41_54_train_info.jbl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "from Functions import LogFunctions as log\n",
    "\n",
    "# Create a entry in log file\n",
    "m_log = log.LogInformation()\n",
    "date = m_log.CreateLogEntry(\"NoveltyDetection\",'SingleClassSVM')\n",
    "\n",
    "# Create a train information file\n",
    "n_folds = 2\n",
    "norm = 'mapstd'\n",
    "#nu_values = np.array([0.7, 0.8, 0.9])\n",
    "#nu_values = np.array([0.001, 0.1, 0.2])\n",
    "nu_values = np.array([0.001, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "gamma_value = 0.1\n",
    "\n",
    "train_info = {}\n",
    "train_info['n_folds'] = n_folds\n",
    "train_info['norm'] = norm\n",
    "train_info['nu_values'] = nu_values\n",
    "train_info['gamma_value'] = gamma_value\n",
    "\n",
    "# divide data in train and test for novelty detection\n",
    "for novelty_class, novelty_label in enumerate(class_labels):\n",
    "    print 'Dividing data in trn and tst for novelty class: %s'%(novelty_label)\n",
    "    CVO = cross_validation.StratifiedKFold(all_trgt[all_trgt!=novelty_class], n_folds)\n",
    "    CVO = list(CVO)\n",
    "    train_info['CVO_novelty_%s'%(novelty_label)] = CVO\n",
    "\n",
    "train_info['train_done'] = False\n",
    "train_info['results_done'] = False\n",
    "\n",
    "train_info_name = result_analysis_path+'/train_info_files'+'/'+date+'_train_info.jbl'\n",
    "joblib.dump([train_info],train_info_name,compress=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'date': '2016_12_01_17_27_33', 'package': 'PCASingleClassSVM'}, 1: {'date': '2016_12_01_17_51_48', 'package': 'PCASingleClassSVM'}, 2: {'date': '2016_12_01_18_09_34', 'package': 'PCASingleClassSVM'}, 3: {'date': '2016_12_01_18_25_15', 'package': 'PCASingleClassSVM'}, 4: {'date': '2016_12_01_19_09_08', 'package': 'PCASingleClassSVM'}, 5: {'date': '2016_12_21_15_11_02', 'package': 'PCASingleClassSVM'}, 6: {'date': '2016_12_21_15_14_37', 'package': 'PCASingleClassSVM'}, 7: {'date': '2016_12_22_14_02_05', 'package': 'PCASingleClassSVM'}, 8: {'date': '2016_12_22_14_03_23', 'package': 'PCASingleClassSVM'}, 9: {'date': '2016_12_22_14_13_41', 'package': 'PCASingleClassSVM'}, 10: {'date': '2016_12_22_14_14_45', 'package': 'PCASingleClassSVM'}, 11: {'date': '2016_12_22_15_27_30', 'package': 'PCASingleClassSVM'}, 12: {'date': '2016_12_22_16_33_54', 'package': 'PCASingleClassSVM'}, 13: {'date': '2016_12_22_17_02_55', 'package': 'PCASingleClassSVM'}, 14: {'date': '2016_12_22_17_13_21', 'package': 'PCASingleClassSVM'}, 15: {'date': '2016_12_24_19_23_04', 'package': 'PCASingleClassSVM'}, 16: {'date': '2016_12_24_19_50_34', 'package': 'PCASingleClassSVM'}, 17: {'date': '2016_12_24_19_50_59', 'package': 'PCASingleClassSVM'}, 18: {'date': '2016_12_24_19_54_20', 'package': 'PCASingleClassSVM'}, 19: {'date': '2016_12_24_20_00_43', 'package': 'PCASingleClassSVM'}, 20: {'date': '2016_12_24_21_47_32', 'package': 'PCASingleClassSVM'}, 21: {'date': '2016_12_24_23_03_14', 'package': 'PCASingleClassSVM'}, 22: {'date': '2016_12_24_23_25_49', 'package': 'PCASingleClassSVM'}, 23: {'date': '2016_12_25_20_24_25', 'package': 'PCDSingleClassSVM'}, 24: {'date': '2016_12_25_20_25_18', 'package': 'PCDSingleClassSVM'}, 25: {'date': '2016_12_25_20_58_23', 'package': 'PCDSingleClassSVM'}, 26: {'date': '2017_02_09_16_44_20', 'package': 'PCASingleClassSVM'}, 27: {'date': '2017_02_11_17_32_40', 'package': 'PCASingleClassSVM'}, 28: {'date': '2017_02_11_17_41_38', 'package': 'PCASingleClassSVM'}, 29: {'date': '2017_02_11_17_42_22', 'package': 'PCASingleClassSVM'}, 30: {'date': '2017_02_11_17_46_00', 'package': 'PCDSingleClassSVM'}, 31: {'date': '2017_02_11_20_21_36', 'package': 'PCDSingleClassSVM'}, 32: {'date': '2017_02_11_20_38_27', 'package': 'PCDSingleClassSVM'}, 33: {'date': '2017_02_11_23_00_31', 'package': 'kPCASingleClassSVM'}, 34: {'date': '2017_02_11_23_00_51', 'package': 'kPCASingleClassSVM'}, 35: {'date': '2017_02_11_23_01_16', 'package': 'kPCASingleClassSVM'}, 36: {'date': '2017_02_11_23_54_50', 'package': 'kPCASingleClassSVM'}, 37: {'date': '2017_02_12_03_31_51', 'package': 'kPCASingleClassSVM'}, 38: {'date': '2017_02_12_03_33_35', 'package': 'PCDSingleClassSVM'}, 39: {'date': '2017_02_16_15_20_38', 'package': 'NLPCASingleClassSVM'}, 40: {'date': '2017_02_16_15_20_45', 'package': 'NLPCASingleClassSVM'}, 41: {'date': '2017_02_16_15_20_59', 'package': 'NLPCASingleClassSVM'}, 42: {'date': '2017_02_17_16_53_57', 'package': 'NLPCASingleClassSVM'}, 43: {'date': '2017_03_17_20_48_09', 'package': 'PCASingleClassSVM'}, 44: {'date': '2017_03_17_20_48_17', 'package': 'PCASingleClassSVM'}, 45: {'date': '2017_03_17_21_16_24', 'package': 'PCDCooperativeSingleClassSVM'}, 46: {'date': '2017_03_17_21_17_20', 'package': 'PCDCooperativeSingleClassSVM'}, 47: {'date': '2017_03_17_21_20_55', 'package': 'PCDInpendentSingleClassSVM'}, 48: {'date': '2017_03_17_21_24_27', 'package': 'kPCASingleClassSVM'}, 49: {'date': '2017_03_17_21_24_47', 'package': 'kPCASingleClassSVM'}, 50: {'date': '2017_03_18_15_17_46', 'package': 'SingleClassSVM'}, 51: {'date': '2017_03_18_15_32_01', 'package': 'kPCASingleClassSVM'}, 52: {'date': '2017_03_18_18_26_56', 'package': 'PCDCooperativeSingleClassSVM'}, 53: {'date': '2017_03_18_19_41_54', 'package': 'SingleClassSVM'}}\n"
     ]
    }
   ],
   "source": [
    "# Read log files\n",
    "from Functions import LogFunctions as log\n",
    "mlog = log.LogInformation()\n",
    "log_entries = mlog.RecoverLogEntries(package_name=\"NoveltyDetection\")\n",
    "print log_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing train performed in 2017_03_18_15_17_46 and for SingleClassSVM analysis\n",
      "SingleClassSVM Train Info File\n",
      "Date: 2017_03_18_15_17_46\n",
      "Number of Folds: 2\n",
      "Normalization Method: mapstd\n",
      "Gamma Value: 0.100\n",
      "Nu Value(s): \n",
      "[ 0.001  0.1    0.2    0.3    0.4    0.5    0.6    0.7    0.8    0.9  ]\n",
      "Train Done: False\n",
      "Extract Results: False\n"
     ]
    }
   ],
   "source": [
    "# Read Information of Train Info File\n",
    "choose_date = '2017_03_18_15_17_46'\n",
    "\n",
    "for log_id, log_entry in enumerate(log_entries):\n",
    "    if log_entries[log_id]['package'] != 'SingleClassSVM':\n",
    "        continue\n",
    "    if log_entries[log_id]['date'] != choose_date:\n",
    "        continue\n",
    "    print 'Analysing train performed in %s and for %s analysis'%(\n",
    "        log_entries[log_id]['date'],log_entries[log_id]['package'])\n",
    "    \n",
    "    # Read train info file\n",
    "    train_info_name = '%s/train_info_files/%s_train_info.jbl'%(\n",
    "        result_analysis_path,log_entries[log_id]['date'])\n",
    "    \n",
    "    [train_info] = joblib.load(train_info_name)\n",
    "    print 'SingleClassSVM Train Info File'\n",
    "    print 'Date: %s'%(choose_date)\n",
    "    print 'Number of Folds: %i'%(train_info['n_folds'])\n",
    "    print 'Normalization Method: %s'%(train_info['norm'])\n",
    "    print 'Gamma Value: %1.3f'%(train_info['gamma_value'])\n",
    "    print 'Nu Value(s): '\n",
    "    print train_info['nu_values']\n",
    "\n",
    "    if train_info['train_done']:\n",
    "        print 'Train Done: True'\n",
    "    else:\n",
    "        print 'Train Done: False'\n",
    "    if train_info['results_done']:\n",
    "        print 'Extract Results: True'\n",
    "    else:\n",
    "        print 'Extract Results: False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 4.05 µs\n",
      "Novelty analysis performed in 2017_03_18_15_17_46 and for SingleClassSVM analysis\n",
      "Training Classifiers: Novelty Class: ClassA, 1 of 2 folds, 1 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 1 of 2 folds, 2 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 1 of 2 folds, 3 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 1 of 2 folds, 4 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 1 of 2 folds, 5 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 1 of 2 folds, 6 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 1 of 2 folds, 7 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 1 of 2 folds, 8 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 1 of 2 folds, 9 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 1 of 2 folds, 10 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 2 of 2 folds, 1 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 2 of 2 folds, 2 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 2 of 2 folds, 3 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 2 of 2 folds, 4 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 2 of 2 folds, 5 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 2 of 2 folds, 6 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 2 of 2 folds, 7 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 2 of 2 folds, 8 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 2 of 2 folds, 9 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassA, 2 of 2 folds, 10 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 1 of 2 folds, 1 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 1 of 2 folds, 2 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 1 of 2 folds, 3 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 1 of 2 folds, 4 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 1 of 2 folds, 5 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 1 of 2 folds, 6 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 1 of 2 folds, 7 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 1 of 2 folds, 8 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 1 of 2 folds, 9 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 1 of 2 folds, 10 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 2 of 2 folds, 1 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 2 of 2 folds, 2 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 2 of 2 folds, 3 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 2 of 2 folds, 4 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 2 of 2 folds, 5 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 2 of 2 folds, 6 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 2 of 2 folds, 7 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 2 of 2 folds, 8 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 2 of 2 folds, 9 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassB, 2 of 2 folds, 10 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 1 of 2 folds, 1 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 1 of 2 folds, 2 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 1 of 2 folds, 3 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 1 of 2 folds, 4 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 1 of 2 folds, 5 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 1 of 2 folds, 6 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 1 of 2 folds, 7 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 1 of 2 folds, 8 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 1 of 2 folds, 9 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 1 of 2 folds, 10 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 2 of 2 folds, 1 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 2 of 2 folds, 2 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 2 of 2 folds, 3 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 2 of 2 folds, 4 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 2 of 2 folds, 5 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 2 of 2 folds, 6 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 2 of 2 folds, 7 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 2 of 2 folds, 8 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 2 of 2 folds, 9 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassC, 2 of 2 folds, 10 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 1 of 2 folds, 1 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 1 of 2 folds, 2 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 1 of 2 folds, 3 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 1 of 2 folds, 4 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 1 of 2 folds, 5 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 1 of 2 folds, 6 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 1 of 2 folds, 7 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 1 of 2 folds, 8 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 1 of 2 folds, 9 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 1 of 2 folds, 10 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 2 of 2 folds, 1 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 2 of 2 folds, 2 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 2 of 2 folds, 3 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 2 of 2 folds, 4 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 2 of 2 folds, 5 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 2 of 2 folds, 6 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 2 of 2 folds, 7 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 2 of 2 folds, 8 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 2 of 2 folds, 9 of 10 nu_values\n",
      "Training Classifiers: Novelty Class: ClassD, 2 of 2 folds, 10 of 10 nu_values\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "size does not fit in an int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-95834533f044>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mclassifier_info_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_analysis_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/classifiers_files'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mchoose_date\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_classifiers.jbl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifier_info_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mtrain_info_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_analysis_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/train_info_files'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mchoose_date\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_train_info.jbl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/natmourajr/.virtualenvs/sonarcessy/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, cache_size, protocol)\u001b[0m\n\u001b[1;32m    402\u001b[0m                                cache_size=cache_size, protocol=protocol)\n\u001b[1;32m    403\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'pickler'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/natmourajr/.virtualenvs/sonarcessy/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                 \u001b[0mwrite_zfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/natmourajr/.virtualenvs/sonarcessy/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mwrite_zfile\u001b[0;34m(file_handle, data, compress)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Store the length of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAX_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: size does not fit in an int"
     ]
    }
   ],
   "source": [
    "# Treinamento do detector de novidade\n",
    "\n",
    "%time\n",
    "\n",
    "# Classifiers\n",
    "classifiers = {}\n",
    "\n",
    "\n",
    "for log_id, log_entry in enumerate(log_entries):\n",
    "    if log_entries[log_id]['package'] != 'SingleClassSVM':\n",
    "        continue\n",
    "    if log_entries[log_id]['date'] != choose_date:\n",
    "        continue\n",
    "    print 'Novelty analysis performed in %s and for %s analysis'%(\n",
    "        log_entries[log_id]['date'],log_entries[log_id]['package'])\n",
    "    \n",
    "    # Read train info file\n",
    "    train_info_name = '%s/train_info_files/%s_train_info.jbl'%(\n",
    "        result_analysis_path,log_entries[log_id]['date'])\n",
    "    \n",
    "    [train_info] = joblib.load(train_info_name)\n",
    "    \n",
    "    # saving time\n",
    "    if train_info['train_done']:\n",
    "        print 'Train done, just analyse it'\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    for novelty_class, novelty_label in enumerate(class_labels):\n",
    "        classifiers[novelty_class] = {}\n",
    "        \n",
    "        known_data = all_data[all_trgt!=novelty_class,:]\n",
    "        known_trgt = all_trgt[all_trgt!=novelty_class]\n",
    "        \n",
    "        # for: folds\n",
    "        for ifold in range(len(train_info['CVO_novelty_%s'%(novelty_label)])):\n",
    "            classifiers[novelty_class][ifold] = {}\n",
    "            \n",
    "            # split data in trn set, tst set\n",
    "            train_id, test_id = train_info['CVO_novelty_%s'%(novelty_label)][ifold]\n",
    "            \n",
    "            # normalize data based in train set\n",
    "            if train_info['norm'] == 'mapstd':\n",
    "                scaler = preprocessing.StandardScaler().fit(known_data[train_id,:])\n",
    "            elif train_info['norm'] == 'mapstd_rob':\n",
    "                scaler = preprocessing.RobustScaler().fit(known_data[train_id,:])\n",
    "            elif train_info['norm'] == 'mapminmax':\n",
    "                scaler = preprocessing.MinMaxScaler().fit(known_data[train_id,:])\n",
    "        \n",
    "            norm_known_data = scaler.transform(known_data)\n",
    "            \n",
    "            for nu_id, nu_value in enumerate(train_info['nu_values']):\n",
    "                classifiers[novelty_class][ifold][nu_value] = {}\n",
    "                print 'Training Classifiers: Novelty Class: %s, %i of %i folds, %i of %i nu_values'%(\n",
    "                    novelty_label, ifold+1, len(train_info['CVO_novelty_%s'%(novelty_label)]),\n",
    "                    nu_id+1, len(train_info['nu_values'])\n",
    "                )\n",
    "                \n",
    "                # novelty detector\n",
    "                novelty_detector = svm.OneClassSVM(nu=nu_value, \n",
    "                                                   kernel=\"rbf\", \n",
    "                                                   gamma=train_info['gamma_value'])\n",
    "                novelty_detector.fit(norm_known_data[train_id,:])\n",
    "                \n",
    "                classifiers[novelty_class][ifold][nu_value]['NoveltyDetector'] = novelty_detector\n",
    "                \n",
    "                # class specialist\n",
    "                for known_class, known_label in enumerate(class_labels):\n",
    "                    if known_class == novelty_class: continue\n",
    "                    class_idx = np.nonzero(known_trgt == known_class)[0]\n",
    "                    idx = np.intersect1d(class_idx,train_id)\n",
    "                    classifier = svm.OneClassSVM(nu=nu_value, kernel=\"rbf\", \n",
    "                                                 gamma=train_info['gamma_value'])\n",
    "                    classifier.fit(norm_known_data[idx,:])\n",
    "                    classifiers[novelty_class][ifold][nu_value][known_label] = classifier\n",
    "\n",
    "    classifier_info_name = result_analysis_path+'/classifiers_files'+'/'+choose_date+'_classifiers.jbl'\n",
    "    joblib.dump([classifiers],classifier_info_name,compress=9)\n",
    "\n",
    "    train_info_name = result_analysis_path+'/train_info_files'+'/'+choose_date+'_train_info.jbl'\n",
    "\n",
    "    train_info['train_done'] = True\n",
    "    joblib.dump([train_info],train_info_name,compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n",
      "PCA analysis performed in 2017_03_18_15_17_46 and for SingleClassSVM analysis\n",
      "Analysing Classifiers: Novelty Class: ClassA, 1 of 2 folds, 1 of 10 nu_values\n"
     ]
    }
   ],
   "source": [
    "# Extração dos resultados\n",
    "%time\n",
    "\n",
    "import scipy.stats as sp_stats\n",
    "\n",
    "for log_id, log_entry in enumerate(log_entries):\n",
    "\n",
    "    if log_entries[log_id]['package'] != 'SingleClassSVM':\n",
    "        continue\n",
    "    if log_entries[log_id]['date'] != choose_date:\n",
    "        continue\n",
    "    print 'PCA analysis performed in %s and for %s analysis'%(\n",
    "        log_entries[log_id]['date'],log_entries[log_id]['package'])\n",
    "    \n",
    "    # Read train info file\n",
    "    train_info_name = '%s/train_info_files/%s_train_info.jbl'%(\n",
    "        result_analysis_path,log_entries[log_id]['date'])\n",
    "    \n",
    "    [train_info] = joblib.load(train_info_name)\n",
    "    \n",
    "    # checking training\n",
    "    #if not train_info['train_done']:\n",
    "    #    print 'Perform Train!!!'\n",
    "    #    continue\n",
    "        \n",
    "    # checking results extraction\n",
    "    #if train_info['results_done']:\n",
    "    #    print 'Extraction done, just analyse it'\n",
    "    #    continue\n",
    "        \n",
    "    #classifier_info_name = result_analysis_path+'/classifiers_files'+'/'+choose_date+'_classifiers.jbl'\n",
    "    #[classifiers] = joblib.load(classifier_info_name)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for novelty_class, novelty_label in enumerate(class_labels):\n",
    "        results[novelty_class] = {}\n",
    "        \n",
    "        # Class Specialist Efficiency\n",
    "        for known_class, known_label in enumerate(class_labels):\n",
    "            if known_class == novelty_class: continue\n",
    "            results[novelty_class][known_label] = np.zeros(\n",
    "                [len(train_info['nu_values']), \n",
    "                 len(train_info['CVO_novelty_%s'%(novelty_label)])])\n",
    "        \n",
    "        # Accuracy\n",
    "        results[novelty_class]['Accuracy'] = np.zeros(\n",
    "            [len(train_info['nu_values']), \n",
    "             len(train_info['CVO_novelty_%s'%(novelty_label)])]) \n",
    "        \n",
    "        # Known SP\n",
    "        results[novelty_class]['Known SP'] = np.zeros(\n",
    "            [len(train_info['nu_values']), \n",
    "             len(train_info['CVO_novelty_%s'%(novelty_label)])])\n",
    "        \n",
    "        # Novelty Detection\n",
    "        results[novelty_class]['Novelty Detection'] = np.zeros(\n",
    "            [len(train_info['nu_values']), \n",
    "             len(train_info['CVO_novelty_%s'%(novelty_label)])])\n",
    "        \n",
    "        # Trigger\n",
    "        results[novelty_class]['Trigger'] = np.zeros(\n",
    "            [len(train_info['nu_values']), \n",
    "             len(train_info['CVO_novelty_%s'%(novelty_label)])])\n",
    "       \n",
    "        # for: folds\n",
    "        for ifold in range(len(train_info['CVO_novelty_%s'%(novelty_label)])):\n",
    "            # split data in trn set, tst set\n",
    "            train_id, test_id = train_info['CVO_novelty_%s'%(novelty_label)][ifold]\n",
    "            \n",
    "            # normalize data based in train set\n",
    "            if train_info['norm'] == 'mapstd':\n",
    "                scaler = preprocessing.StandardScaler().fit(known_data[train_id,:])\n",
    "            elif train_info['norm'] == 'mapstd_rob':\n",
    "                scaler = preprocessing.RobustScaler().fit(known_data[train_id,:])\n",
    "            elif train_info['norm'] == 'mapminmax':\n",
    "                scaler = preprocessing.MinMaxScaler().fit(known_data[train_id,:])\n",
    "        \n",
    "            norm_all_data = scaler.transform(all_data)\n",
    "        \n",
    "            for nu_id, nu_value in enumerate(train_info['nu_values']):\n",
    "                print 'Analysing Classifiers: Novelty Class: %s, %i of %i folds, %i of %i nu_values'%(\n",
    "                    novelty_label, ifold+1, len(train_info['CVO_novelty_%s'%(novelty_label)]),\n",
    "                    nu_id+1, len(train_info['nu_values'])\n",
    "                )\n",
    "                \n",
    "                # class specialist\n",
    "                for known_class, known_label in enumerate(class_labels):\n",
    "                    if known_class == novelty_class: continue\n",
    "                    output = (classifiers[novelty_class]\n",
    "                              [ifold][nu_value]\n",
    "                              [known_label].predict(norm_all_data[all_trgt==known_class]))\n",
    "                    \n",
    "                    results[novelty_class][known_label][nu_id,ifold] = (\n",
    "                    float(sum(output==1))/float(output.shape[0]))\n",
    "                \n",
    "                # accuracy\n",
    "                buff = np.zeros([len(class_labels)-1,1])\n",
    "                for known_class, known_label in enumerate(class_labels):\n",
    "                    if known_class == novelty_class: continue\n",
    "                    buff[known_class-(known_class>novelty_class)] = (\n",
    "                        results[novelty_class][known_label][nu_id,ifold])\n",
    "                results[novelty_class]['Accuracy'][nu_id,ifold] = np.mean(buff,axis=0)\n",
    "                \n",
    "                # known sp\n",
    "                results[novelty_class]['Known SP'][nu_id,ifold] = (np.sqrt(np.mean(buff,axis=0)\n",
    "                                                                           *sp_stats.gmean(buff,axis=0)))\n",
    "                \n",
    "                # novelty detection\n",
    "                output = (classifiers[novelty_class]\n",
    "                          [ifold][nu_value]\n",
    "                          ['NoveltyDetector'].predict(norm_all_data\n",
    "                                                [all_trgt==novelty_class]))\n",
    "                results[novelty_class]['Novelty Detection'][nu_id,ifold] = (\n",
    "                float(sum(output==-1))/float(output.shape[0]))\n",
    "                \n",
    "                # trigger\n",
    "                output = (classifiers[novelty_class]\n",
    "                          [ifold][nu_value]\n",
    "                          ['NoveltyDetector'].predict(norm_all_data\n",
    "                                                [all_trgt!=novelty_class]))\n",
    "                results[novelty_class]['Trigger'][nu_id,ifold] = (\n",
    "                float(sum(output==1))/float(output.shape[0]))\n",
    "                \n",
    "    result_file_path = result_analysis_path+'/result_files'+'/'+choose_date+'_results.jbl'\n",
    "    joblib.dump([results],result_file_path,compress=9)\n",
    "\n",
    "    train_info_name = result_analysis_path+'/train_info_files'+'/'+choose_date+'_train_info.jbl'\n",
    "\n",
    "    train_info['results_done'] = True\n",
    "    joblib.dump([train_info],train_info_name,compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n",
      "PCA analysis performed in 2017_03_18_15_17_46 and for SingleClassSVM analysis\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Error -5 while decompressing data: incomplete or truncated stream",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ef19bd892dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mclassifier_info_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_analysis_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/classifiers_files'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mchoose_date\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_classifiers.jbl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_info_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mresult_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_analysis_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/result_files'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mchoose_date\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_results.jbl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/natmourajr/.virtualenvs/sonarcessy/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    451\u001b[0m                               \u001b[0;34m'ignoring mmap_mode \"%(mmap_mode)s\" flag passed'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                               % locals(), Warning, stacklevel=2)\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipNumpyUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             unpickler = NumpyUnpickler(filename, file_handle=file_handle,\n",
      "\u001b[0;32m/home/natmourajr/.virtualenvs/sonarcessy/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, file_handle)\u001b[0m\n\u001b[1;32m    337\u001b[0m         NumpyUnpickler.__init__(self, filename,\n\u001b[1;32m    338\u001b[0m                                 \u001b[0mfile_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                                 mmap_mode=None)\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/natmourajr/.virtualenvs/sonarcessy/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, file_handle, mmap_mode)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0mUnpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/natmourajr/.virtualenvs/sonarcessy/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36m_open_pickle\u001b[0;34m(self, file_handle)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_zfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/natmourajr/.virtualenvs/sonarcessy/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mread_zfile\u001b[0;34m(file_handle)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# We use the known length of the data to tell Zlib the size of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# buffer to allocate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     assert len(data) == length, (\n\u001b[1;32m     91\u001b[0m         \u001b[0;34m\"Incorrect data length while decompressing %s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: Error -5 while decompressing data: incomplete or truncated stream"
     ]
    }
   ],
   "source": [
    "# Analise dos resultados\n",
    "%time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['legend.numpoints'] = 1\n",
    "plt.rcParams['legend.handlelength'] = 3\n",
    "plt.rcParams['legend.borderpad'] = 0.3\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "for log_id, log_entry in enumerate(log_entries):\n",
    "    if log_entries[log_id]['package'] != 'SingleClassSVM':\n",
    "        continue\n",
    "    if log_entries[log_id]['date'] != choose_date:\n",
    "        continue\n",
    "    print 'PCA analysis performed in %s and for %s analysis'%(\n",
    "        log_entries[log_id]['date'],log_entries[log_id]['package'])\n",
    "    \n",
    "    # Read train info file\n",
    "    train_info_name = '%s/train_info_files/%s_train_info.jbl'%(\n",
    "        result_analysis_path,log_entries[log_id]['date'])\n",
    "    \n",
    "    [train_info] = joblib.load(train_info_name)\n",
    "          \n",
    "    # checking training\n",
    "    #if not train_info['train_done']:\n",
    "    #    print 'Perform Train!!!'\n",
    "    #    continue\n",
    "        \n",
    "    # checking results extraction\n",
    "    if not train_info['results_done']:\n",
    "        print 'Perform Extraction!!!'\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    classifier_info_name = result_analysis_path+'/classifiers_files'+'/'+choose_date+'_classifiers.jbl'\n",
    "    [classifiers] = joblib.load(classifier_info_name)\n",
    "    \n",
    "    result_file_path = result_analysis_path+'/result_files'+'/'+choose_date+'_results.jbl'\n",
    "    [results] = joblib.load(result_file_path)\n",
    "    \n",
    "    # Plot Efficiency\n",
    "    fig, subplot_array = plt.subplots(nrows=2, ncols=2,figsize=(20,20))\n",
    "    m_colors = ['b', 'r', 'g', 'y']\n",
    "    for novelty_class, novelty_label in enumerate(class_labels):\n",
    "        ax = plt.subplot(2,2,novelty_class+1)\n",
    "        m_fontsize = 18\n",
    "        plt.title('Classifier Eff. - Novelty: '+novelty_label, fontsize= m_fontsize, fontweight=\"bold\")\n",
    "        if novelty_class > -1:\n",
    "            plt.xlabel(r'$\\nu$ values', fontsize= m_fontsize, fontweight=\"bold\")\n",
    "        plt.ylabel('Efficiency(%)', fontsize= m_fontsize, fontweight=\"bold\")\n",
    "        m_leg = []\n",
    "        \n",
    "        line_width = 3.5\n",
    "        \n",
    "        # class specialist eff\n",
    "        for known_class, known_label in enumerate(class_labels):\n",
    "            if known_class == novelty_class: continue\n",
    "            plot_data = results[novelty_class][known_label]\n",
    "            ax.errorbar(train_info['nu_values'],\n",
    "                        100*np.mean(plot_data,axis=1),\n",
    "                        100*np.std(plot_data,axis=1),marker='o',\n",
    "                        color=m_colors[known_class],alpha=0.5,linewidth=line_width)\n",
    "            m_leg.append(known_label+' Eff.')\n",
    "        \n",
    "        # accuracy\n",
    "        plot_data = results[novelty_class]['Accuracy']\n",
    "        ax.errorbar(train_info['nu_values'],\n",
    "                    100*np.mean(plot_data,axis=1),\n",
    "                    100*np.std(plot_data,axis=1),marker='o',\n",
    "                    color='k',ls='-.',alpha=0.5, linewidth=line_width)\n",
    "        m_leg.append('Known Acc.')\n",
    "        \n",
    "        # known sp\n",
    "        plot_data = results[novelty_class]['Known SP']\n",
    "        ax.errorbar(train_info['nu_values'],\n",
    "                    100*np.mean(plot_data,axis=1),\n",
    "                    100*np.std(plot_data,axis=1),marker='o',\n",
    "                    color='k',ls='-.',alpha=0.5, linewidth=line_width)\n",
    "        m_leg.append('Known SP')\n",
    "        \n",
    "        # trigger\n",
    "        plot_data = results[novelty_class]['Trigger']\n",
    "        ax.errorbar(train_info['nu_values'],\n",
    "                    100*np.mean(plot_data,axis=1),\n",
    "                    100*np.std(plot_data,axis=1),marker='o',\n",
    "                    color='k',ls=':',alpha=0.5, linewidth=line_width)\n",
    "        m_leg.append('Trigger')\n",
    "        \n",
    "        # novelty detection\n",
    "        plot_data = results[novelty_class]['Novelty Detection']\n",
    "        ax.errorbar(train_info['nu_values'],\n",
    "                    100*np.mean(plot_data,axis=1),\n",
    "                    100*np.std(plot_data,axis=1),marker='o',\n",
    "                    color='k',ls='-',alpha=0.5, linewidth=line_width)\n",
    "        m_leg.append('Novelty Detection')\n",
    "        \n",
    "        # graphical assusts\n",
    "        ax.set_ylim([0.0, 115])\n",
    "        ax.set_yticks([x for x in range(0,101,5)])\n",
    "        \n",
    "        ax.set_xlim([np.min(train_info['nu_values']), np.max(train_info['nu_values'])])\n",
    "        ax.set_xticks(train_info['nu_values'])\n",
    "        ax.set_xticklabels(train_info['nu_values'],rotation=45)\n",
    "        \n",
    "        ax.grid()\n",
    "        ax.legend(m_leg, loc='upper right',ncol=3)\n",
    "    fig.savefig(result_analysis_path+'/picts/'+choose_date+'_'+\n",
    "                log_entries[log_id]['package']+'_novelty_detection.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: {0.001: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.10000000000000001: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.20000000000000001: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.29999999999999999: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.40000000000000002: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.5: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.59999999999999998: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.69999999999999996: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.80000000000000004: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.90000000000000002: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)}},\n",
       "  1: {0.001: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.10000000000000001: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.20000000000000001: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.29999999999999999: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.40000000000000002: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.5: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.59999999999999998: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.69999999999999996: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.80000000000000004: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.90000000000000002: {'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)}}},\n",
       " 1: {0: {0.001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.10000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.20000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.29999999999999999: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.40000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.5: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.59999999999999998: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.69999999999999996: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.80000000000000004: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.90000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)}},\n",
       "  1: {0.001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.10000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.20000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.29999999999999999: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.40000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.5: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.59999999999999998: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.69999999999999996: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.80000000000000004: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.90000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)}}},\n",
       " 2: {0: {0.001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.10000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.20000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.29999999999999999: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.40000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.5: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.59999999999999998: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.69999999999999996: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.80000000000000004: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.90000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)}},\n",
       "  1: {0.001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.10000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.20000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.29999999999999999: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.40000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.5: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.59999999999999998: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.69999999999999996: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.80000000000000004: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.90000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassD': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)}}},\n",
       " 3: {0: {0.001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.10000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.20000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.29999999999999999: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.40000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.5: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.59999999999999998: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.69999999999999996: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.80000000000000004: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.90000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)}},\n",
       "  1: {0.001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.001, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.10000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.10000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.20000000000000001: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.20000000000000001, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.29999999999999999: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.29999999999999999, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.40000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.40000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.5: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "          verbose=False)},\n",
       "   0.59999999999999998: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.59999999999999998, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.69999999999999996: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.69999999999999996, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.80000000000000004: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.80000000000000004, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)},\n",
       "   0.90000000000000002: {'ClassA': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassB': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'ClassC': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False),\n",
       "    'NoveltyDetector': OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "          max_iter=-1, nu=0.90000000000000002, random_state=None,\n",
       "          shrinking=True, tol=0.001, verbose=False)}}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
